{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMUccm4KGGoQ2JlrliRCYZv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDlGXh5DCX15","executionInfo":{"status":"ok","timestamp":1754346740803,"user_tz":-120,"elapsed":3187,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"4f3f3656-6d44-46a2-ffd7-10c913a48615"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.11.13\n","CUDA available: True | device: Tesla T4\n"]}],"source":["import torch, platform, os\n","print(\"Python\", platform.python_version())\n","print(\"CUDA available:\", torch.cuda.is_available(), \"| device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["!git clone --depth 1 https://github.com/KEggensperger/DistNet\n","!git clone --depth 1 https://github.com/PriorLabs/TabPFN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZY4Zm-BCab6","executionInfo":{"status":"ok","timestamp":1754346743149,"user_tz":-120,"elapsed":2333,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"1efbb2fb-f4b0-459c-e5e8-5350e0f078e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DistNet'...\n","remote: Enumerating objects: 25, done.\u001b[K\n","remote: Counting objects: 100% (25/25), done.\u001b[K\n","remote: Compressing objects: 100% (21/21), done.\u001b[K\n","remote: Total 25 (delta 1), reused 25 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (25/25), 27.79 KiB | 836.00 KiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n","Cloning into 'TabPFN'...\n","remote: Enumerating objects: 105, done.\u001b[K\n","remote: Counting objects: 100% (105/105), done.\u001b[K\n","remote: Compressing objects: 100% (93/93), done.\u001b[K\n","remote: Total 105 (delta 10), reused 63 (delta 8), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (105/105), 1.48 MiB | 5.27 MiB/s, done.\n","Resolving deltas: 100% (10/10), done.\n"]}]},{"cell_type":"code","source":["%pip install -q --force-reinstall \"torch==2.2.2\" \"torchvision==0.17.2\" \"torchaudio==2.2.2\"\n","%pip install -q --force-reinstall \"numpy==1.26.4\" \"ConfigSpace==1.2.1\"\n","%pip install -q tabpfn tabpfn-extensions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xbg6HbbHCcdm","executionInfo":{"status":"ok","timestamp":1754346919815,"user_tz":-120,"elapsed":176665,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"da22f074-c001-4b9e-d69e-61c0548e58d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.7.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.7.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.7.0 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.6/160.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import numpy, torch, tabpfn\n","print(\"NumPy :\", numpy.__version__)   # should be 1.26.4\n","print(\"Torch :\", torch.__version__)   # should be 2.2.2\n","print(\"TabPFN:\", tabpfn.__version__)  # 2.1.0 (or newer if you upgraded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiDX5XsOUjO7","executionInfo":{"status":"ok","timestamp":1754347080797,"user_tz":-120,"elapsed":3784,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"e1d1afa3-b699-429c-a58f-4745ab027a6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NumPy : 1.26.4\n","Torch : 2.2.2+cu121\n","TabPFN: 2.1.1\n"]}]},{"cell_type":"code","source":["import sys, pathlib\n","sys.path.append(str(pathlib.Path(\"DistNet\").resolve()))\n","print(\"Paths ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxWFGKwFUje8","executionInfo":{"status":"ok","timestamp":1754347080823,"user_tz":-120,"elapsed":11,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"634047bf-734c-4429-ecdb-6e511298ec9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Paths ready.\n"]}]},{"cell_type":"code","source":["%%bash\n","python - <<'PY'\n","import sys, pathlib\n","sys.path.append(str(pathlib.Path(\"DistNet\").resolve()))\n","print(\"Paths ready.\")\n","PY"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlM4XcxAUrtF","executionInfo":{"status":"ok","timestamp":1754347080861,"user_tz":-120,"elapsed":37,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"8468628e-2824-44fc-b4b5-776690119da1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Paths ready.\n"]}]},{"cell_type":"code","source":["%%bash\n","cd DistNet\n","curl -L -o DistNetData.zip \"http://www.ml4aad.org/wp-content/uploads/2018/04/DistNetData.zip\"\n","unzip -q DistNetData.zip -d data\n","mv data/DistNetData/* data/\n","rm -rf data/DistNetData DistNetData.zip\n","cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie1R5hviEr00","executionInfo":{"status":"ok","timestamp":1754347106744,"user_tz":-120,"elapsed":25882,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"0ef2708c-a54e-4285-84fa-447b50e62301"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0  181M    0  132k    0     0  79514      0  0:40:00  0:00:01  0:39:59 79502\r  1  181M    1 2317k    0     0   841k      0  0:03:41  0:00:02  0:03:39  841k\r  6  181M    6 11.5M    0     0  3282k      0  0:00:56  0:00:03  0:00:53 3282k\r 13  181M   13 25.2M    0     0  5573k      0  0:00:33  0:00:04  0:00:29 5573k\r 21  181M   21 38.2M    0     0  6874k      0  0:00:27  0:00:05  0:00:22 7736k\r 27  181M   27 50.6M    0     0  7698k      0  0:00:24  0:00:06  0:00:18 10.0M\r 35  181M   35 63.8M    0     0  8391k      0  0:00:22  0:00:07  0:00:15 12.2M\r 41  181M   41 74.7M    0     0  8869k      0  0:00:21  0:00:08  0:00:13 12.5M\r 48  181M   48 88.6M    0     0  9378k      0  0:00:19  0:00:09  0:00:10 12.5M\r 55  181M   55  101M    0     0  9728k      0  0:00:19  0:00:10  0:00:09 12.6M\r 63  181M   63  115M    0     0   9.8M      0  0:00:18  0:00:11  0:00:07 12.8M\r 68  181M   68  124M    0     0   9.9M      0  0:00:18  0:00:12  0:00:06 12.6M\r 74  181M   74  135M    0     0   9.9M      0  0:00:18  0:00:13  0:00:05 12.1M\r 80  181M   80  147M    0     0  10.0M      0  0:00:18  0:00:14  0:00:04 11.6M\r 87  181M   87  158M    0     0  10.0M      0  0:00:18  0:00:15  0:00:03 11.3M\r 93  181M   93  170M    0     0  10.1M      0  0:00:17  0:00:16  0:00:01 11.0M\r 99  181M   99  180M    0     0  10.2M      0  0:00:17  0:00:17 --:--:-- 11.1M\r100  181M  100  181M    0     0  10.3M      0  0:00:17  0:00:17 --:--:-- 11.6M\n"]}]},{"cell_type":"code","source":["# ⬇️ Writes DistNet/scripts/eval_tabpfn_iid.py to report NLL in Standardized (Z-score) space\n","from textwrap import dedent\n","from pathlib import Path\n","\n","code = dedent(r'''\n","#!/usr/bin/env python3\n","import argparse, os, pickle, sys, pathlib\n","import numpy as np\n","import torch\n","from tabpfn import TabPFNRegressor\n","\n","# Make DistNet modules importable regardless of CWD\n","ROOT = pathlib.Path(__file__).resolve().parent.parent\n","sys.path.insert(0, str(ROOT))\n","\n","from helper import load_data, preprocess, data_source_release\n","from sklearn.model_selection import KFold\n","\n","\n","def predict_nll(reg,\n","                X_vl_flat32,\n","                Y_vl_flat32_transformed,\n","                batch_size: int = 4096):\n","    \"\"\"\n","    Compute continuous NLL in batches on the transformed (standardized) data.\n","    \"\"\"\n","    n = X_vl_flat32.shape[0]\n","    out_chunks, pos = [], 0\n","    eps = 1e-12\n","\n","    while pos < n:\n","        end = min(pos + batch_size, n)\n","        with torch.no_grad():\n","            full = reg.predict(X_vl_flat32[pos:end], output_type=\"full\")\n","\n","            criterion = full.get(\"criterion\", None) or getattr(reg, \"renormalized_criterion_\", None) or getattr(reg, \"bardist_\", None)\n","            if criterion is None:\n","                raise RuntimeError(\"TabPFN criterion not found. Update tabpfen or keep output_type='full'.\")\n","\n","            dev = criterion.borders.device\n","            logits = torch.as_tensor(full[\"logits\"], device=dev, dtype=torch.float32)\n","            y_true_transformed = torch.as_tensor(Y_vl_flat32_transformed[pos:end], device=dev, dtype=torch.float32).view(-1)\n","\n","            # NLL in transformed (Z-score) space\n","            pdf_transformed = criterion.pdf(logits, y_true_transformed).clamp_min(eps)\n","            nll = -torch.log(pdf_transformed)\n","\n","        out_chunks.append(nll.detach().cpu())\n","        pos = end\n","\n","    return torch.cat(out_chunks, dim=0).numpy()\n","\n","\n","def main():\n","    p = argparse.ArgumentParser()\n","    sc_dict = data_source_release.get_sc_dict()\n","    p.add_argument(\"--scenario\", required=True, choices=sc_dict.keys())\n","    p.add_argument(\"--fold\", type=int, required=True)\n","    p.add_argument(\"--save\", required=True)\n","\n","    p.add_argument(\"--subsample_mode\", choices=[\"first\", \"flattened_random\", \"instance_wise\"], default=\"instance_wise\",\n","                   help=\"Subsampling strategy. 'instance_wise' is recommended for better results.\")\n","    p.add_argument(\"--cap_rows\", type=int, default=4096,\n","                   help=\"Max training context rows. For instance_wise, this is used to calculate the number of instances to sample.\")\n","    p.add_argument(\"--passes\", type=int, default=2,\n","                   help=\"Repeat iid subsample + re-fit and average NLLs for more stable results.\")\n","    p.add_argument(\"--val_batch\", type=int, default=4096)\n","    p.add_argument(\"--seed\", type=int, default=1)\n","\n","    args = p.parse_args()\n","    assert 0 <= args.fold <= 9\n","\n","    print(f\">> TabPFN (Subsample: {args.subsample_mode}): Standardization (Z-score). NLL in STANDARDIZED space.\")\n","\n","    data_dir = data_source_release.get_data_dir()\n","    runtimes, features, _ = load_data.get_data(\n","        scenario=args.scenario, data_dir=data_dir,\n","        sc_dict=sc_dict, retrieve=sc_dict[args.scenario][\"use\"])\n","\n","    X, Y = np.asarray(features), np.asarray(runtimes)\n","\n","    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n","    tr_idx, vl_idx = list(kf.split(np.arange(X.shape[0])))[args.fold]\n","\n","    X_tr_raw, X_vl_raw = X[tr_idx], X[vl_idx]\n","    Y_tr_raw, Y_vl_raw = Y[tr_idx], Y[vl_idx]\n","\n","    X_tr, X_vl = preprocess.preprocess_features(X_tr_raw, X_vl_raw, scal=\"meanstd\")\n","    n_reps = Y_tr_raw.shape[1]\n","\n","    X_tr_flat = np.repeat(X_tr, n_reps, axis=0).astype(np.float32)\n","    Y_tr_flat = Y_tr_raw.flatten().astype(np.float32)\n","    X_vl_flat = np.repeat(X_vl, n_reps, axis=0).astype(np.float32)\n","    Y_vl_flat = Y_vl_raw.flatten().astype(np.float32)\n","\n","    # Standardize targets using Mean and Std Dev from TRAINING data\n","    train_mean = np.mean(Y_tr_flat)\n","    train_std = np.std(Y_tr_flat)\n","    if train_std < 1e-8:\n","        train_std = 1.0\n","\n","    Y_tr_flat_std = ((Y_tr_flat - train_mean) / train_std).astype(np.float32)\n","    Y_vl_flat_std = ((Y_vl_flat - train_mean) / train_std).astype(np.float32)\n","\n","    print(f\"  Train Mean: {train_mean:.4f}, Train Std Dev: {train_std:.4f}\")\n","\n","    nll_passes = []\n","    for pass_id in range(args.passes):\n","        rng_pass = np.random.RandomState(args.seed + pass_id)\n","\n","        if args.subsample_mode == \"instance_wise\":\n","            n_instances_tr = X_tr.shape[0]\n","            n_instances_to_sample = max(1, min(n_instances_tr, args.cap_rows // n_reps))\n","            print(f\"  [Pass {pass_id+1}/{args.passes}] Sampling {n_instances_to_sample}/{n_instances_tr} instances...\")\n","\n","            sub_instance_idx = rng_pass.choice(n_instances_tr, size=n_instances_to_sample, replace=True)\n","\n","            X_sub_instances = X_tr[sub_instance_idx]\n","            Y_tr_std = Y_tr_flat_std.reshape(Y_tr_raw.shape)\n","            Y_sub_instances_std = Y_tr_std[sub_instance_idx]\n","\n","            X_sub = np.repeat(X_sub_instances, n_reps, axis=0).astype(np.float32)\n","            Y_sub = Y_sub_instances_std.flatten().astype(np.float32)\n","\n","        else: # flattened_random or first\n","            N_flat = X_tr_flat.shape[0]\n","            cap = min(args.cap_rows, N_flat)\n","            print(f\"  [Pass {pass_id+1}/{args.passes}] Sampling {cap}/{N_flat} rows...\")\n","            sub_idx = rng_pass.choice(N_flat, size=cap, replace=True)\n","            X_sub, Y_sub = X_tr_flat[sub_idx], Y_tr_flat_std[sub_idx]\n","\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        reg = TabPFNRegressor(device=device, ignore_pretraining_limits=True)\n","        reg.fit(X_sub, Y_sub)\n","\n","        nll_rep = predict_nll(reg, X_vl_flat, Y_vl_flat_std, batch_size=args.val_batch)\n","        val_pred = nll_rep.reshape(-1, n_reps).mean(axis=1)\n","        nll_passes.append(val_pred)\n","\n","    val_pred_mean = np.mean(np.stack(nll_passes, axis=0), axis=0)\n","\n","    os.makedirs(args.save, exist_ok=True)\n","    add_info = {\n","        \"scenario\": args.scenario, \"fold\": args.fold, \"model\": \"tabpfn\",\n","        \"cap_rows\": args.cap_rows, \"passes\": args.passes, \"subsample_mode\": args.subsample_mode,\n","        \"seed\": args.seed, \"y_transform\": \"standardize\", \"report_space\": \"standardized_zscore_space\",\n","        \"scale_meta\": {\"transform\": \"zscore\", \"train_mean\": train_mean, \"train_std\": train_std}\n","    }\n","    filename = (f\"{args.scenario}.full.tabpfn.sample_{args.subsample_mode}\"\n","                f\".cap{args.cap_rows}.passes{args.passes}.fold{args.fold}.rep_standardized_space.pkl\")\n","    fp = os.path.join(args.save, filename)\n","\n","    with open(fp, \"wb\") as fh:\n","        pickle.dump([None, val_pred_mean, add_info], fh, protocol=pickle.HIGHEST_PROTOCOL)\n","    print(f\"Saved {fp} | Mean NLL: {float(np.mean(val_pred_mean)):.4f}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n","''')\n","\n","Path(\"DistNet/scripts\").mkdir(parents=True, exist_ok=True)\n","Path(\"DistNet/scripts/eval_tabpfn_iid.py\").write_text(code)\n","print(\"NLL is now reported in the Standardized (Z-score) space with NO correction.\")"],"metadata":{"id":"67bkZSdWCe88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# uninstall first to avoid mixups\n","%pip uninstall -y torch torchvision torchaudio\n","\n","# install cu121 wheels for 2.5.1\n","%pip install -q --no-cache-dir --force-reinstall \\\n","  --index-url https://download.pytorch.org/whl/cu121 \\\n","  \"torch==2.5.1\" \"torchvision==0.20.1\" \"torchaudio==2.5.1\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZFGmvm-a86Z","executionInfo":{"status":"ok","timestamp":1754347456228,"user_tz":-120,"elapsed":121145,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"cdb3afe1-e773-4064-be94-2ecc88989cd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.5.1+cu121\n","Uninstalling torch-2.5.1+cu121:\n","  Successfully uninstalled torch-2.5.1+cu121\n","Found existing installation: torchvision 0.20.1+cu121\n","Uninstalling torchvision-0.20.1+cu121:\n","  Successfully uninstalled torchvision-0.20.1+cu121\n","Found existing installation: torchaudio 2.5.1+cu121\n","Uninstalling torchaudio-2.5.1+cu121:\n","  Successfully uninstalled torchaudio-2.5.1+cu121\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m146.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m228.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m279.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m343.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m340.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m264.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m157.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n","typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\n","pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["%pip install -q tabpfn tabpfn-extensions"],"metadata":{"id":"GhSojgQdQoXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import tabpfn  # <-- This line was missing\n","\n","print(\"Torch :\", torch.__version__)\n","print(\"TabPFN:\", tabpfn.__version__, \"from\", tabpfn.__file__)\n","\n","# The check for 'enable_gqa' is removed.\n","# The tabpfen library automatically uses the optimized attention mechanism\n","# available in the installed PyTorch version (2.5.1), so this check is not needed.\n","print(\"\\nPyTorch version 2.5.1 installed, which includes optimized attention backends for TabPFN.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYcPiaxzYAdl","executionInfo":{"status":"ok","timestamp":1754347651028,"user_tz":-120,"elapsed":8,"user":{"displayName":"Gurmeher Singh","userId":"04142282654721528271"}},"outputId":"bf07b628-4853-446a-b570-348ba97036b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch : 2.5.1+cu121\n","TabPFN: 2.1.1 from /usr/local/lib/python3.11/dist-packages/tabpfn/__init__.py\n","\n","PyTorch version 2.5.1 installed, which includes optimized attention backends for TabPFN.\n"]}]},{"cell_type":"code","source":["!python DistNet/scripts/eval_tabpfn_iid.py \\\n","  --scenario clasp_factoring \\\n","  --fold 0 \\\n","  --save results_sanity_check \\\n","  --cap_rows 2048 \\\n","  --passes 1 \\\n","  --subsample_mode instance_wise \\\n","  --val_batch 4096 \\\n","  --seed 1"],"metadata":{"id":"4jXaVSl3QGNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 🔁 Run TabPFN (log1p target, original-space NLL, i.i.d. subsampling) across scenarios × 10 folds\n","\n","SCENARIOS = [\n","    \"clasp_factoring\",\n","    \"spear_qcp\",\n","    \"yalsat_qcp\",\n","    \"lpg-zeno\",\n","]\n","\n","SAVE_ROOT  = \"results_iid\"   # scenario subfolders will be created\n","CAP_ROWS   = 4096            # iid context size per fold (increase if VRAM allows)\n","PASSES     = 2               # independent iid subsamples to average\n","SUBSAMPLE  = \"random\"        # i.i.d. subsampling (with replacement handled inside the script)\n","VAL_BATCH  = 4096            # reduce if you hit OOM\n","SEED       = 1\n","\n","import subprocess, os, sys, time\n","\n","os.makedirs(SAVE_ROOT, exist_ok=True)\n","t_all = time.time()\n","\n","for sc in SCENARIOS:\n","    save_dir = os.path.join(SAVE_ROOT, sc)\n","    os.makedirs(save_dir, exist_ok=True)\n","    print(f\"\\n=== Scenario: {sc} ===\")\n","    t0 = time.time()\n","\n","    for fold in range(10):\n","        print(f\"→ fold {fold}\")\n","        cmd = [\n","            sys.executable, \"DistNet/scripts/eval_tabpfn_iid.py\",\n","            \"--scenario\", sc,\n","            \"--fold\", str(fold),\n","            \"--save\", save_dir,\n","            \"--cap_rows\", str(CAP_ROWS),\n","            \"--passes\", str(PASSES),\n","            \"--subsample_mode\", SUBSAMPLE,   # default is 'random', kept explicit\n","            \"--val_batch\", str(VAL_BATCH),\n","            \"--seed\", str(SEED),\n","            # no --y_transform / --report_space flags needed (defaults handle it)\n","        ]\n","        try:\n","            subprocess.run(cmd, check=True)\n","        except subprocess.CalledProcessError as e:\n","            print(f\"✗ fold {fold} failed (exit {e.returncode}); continuing…\")\n","\n","    print(f\"✔ finished {sc} in {(time.time()-t0)/60:.1f} min\")\n","\n","print(f\"\\n✔ all scenarios done in {(time.time()-t_all)/3600:.2f} h\")"],"metadata":{"id":"gULYuHAZNgD7"},"execution_count":null,"outputs":[]}]}